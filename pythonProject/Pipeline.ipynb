{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T14:41:33.258015Z",
     "start_time": "2025-12-28T14:41:33.035302Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "class BaseDataPreprocessor(TransformerMixin, BaseEstimator):\n",
    "        \n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.needed_columns = needed_columns\n",
    "        \n",
    "    \n",
    "    def fit(self, data, *args):\n",
    "        X = data[self.needed_columns] if self.needed_columns is not None else data\n",
    "        X = pd.DataFrame(X).fillna(0)\n",
    "        self.scaler.fit(X)\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        X = data[self.needed_columns] if self.needed_columns is not None else data\n",
    "        X = pd.DataFrame(X).fillna(0)\n",
    "        return self.scaler.transform(X)\n",
    "            \n",
    "class OneHotPreprocessor(BaseDataPreprocessor):\n",
    "    \n",
    "    def __init__(self,interesting_columns: Optional[List[str]]=None, **kwargs):\n",
    "        super(OneHotPreprocessor, self).__init__(**kwargs)\n",
    "        self.interesting_columns =  interesting_columns\n",
    "        self.ohe = OneHotEncoder(sparse_output=False,handle_unknown='ignore')\n",
    "        \n",
    "    def fit(self, data, *args):\n",
    "        if self.needed_columns is None:\n",
    "            self.needed_columns = data.drop(self.interesting_columns, axis=1).columns.tolist()\n",
    "            \n",
    "        super().fit(data, *args)\n",
    "        if self.interesting_columns is not None:\n",
    "            self.ohe.fit(data[self.interesting_columns])\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X_scaled = super().transform(data)\n",
    "        if self.interesting_columns is not None:\n",
    "            X_encoded = self.ohe.transform(data[self.interesting_columns])\n",
    "            return np.hstack((X_scaled, X_encoded))\n",
    "        return X_scaled\n",
    "    \n",
    "def grad(X, w, b, y, reg):\n",
    "    grad_w =  (2/X.shape[0])*(X.T @ (X @ w + b - y)) +2*reg*w\n",
    "    grad_b = (2/X.shape[0])*np.sum(X @ w + b - y)\n",
    "    return grad_w,grad_b\n",
    "\n",
    "class SGDLinearRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self,\n",
    "                 lr=0.01, regularization=1., delta_converged=1e-3, max_steps=1000,\n",
    "                 batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.max_steps = int(max_steps)\n",
    "        self.delta_converged = delta_converged\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.is_fitted_ = False\n",
    "\n",
    "        self.W_ = None\n",
    "        self.b_ = None\n",
    "    def fit(self, X, Y):\n",
    "        self.W_ = np.ones(X.shape[1])\n",
    "        self.b_ = 1\n",
    "        Y = np.array(Y).ravel()\n",
    "        X = np.array(X)\n",
    "        converged = False\n",
    "        step = 0\n",
    "        if self.batch_size > X.shape[0]:\n",
    "            self.batch_size = X.shape[0]\n",
    "        while step < self.max_steps:\n",
    "            indices = np.random.permutation(X.shape[0])\n",
    "            for i in range(0,X.shape[0],self.batch_size):\n",
    "                idx = indices[i:i + self.batch_size]\n",
    "                X_batch, Y_batch = X[idx], Y[idx]\n",
    "                grad_w, grad_b = grad(X_batch, self.W_, self.b_, Y_batch, self.regularization)\n",
    "                if step >= self.max_steps or np.linalg.norm(self.lr*grad_w) < self.delta_converged:\n",
    "                    converged = True\n",
    "                    break\n",
    "                self.W_ -= self.lr*grad_w\n",
    "                self.b_ -= self.lr*grad_b\n",
    "                step += 1\n",
    "            if converged:\n",
    "                break\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X,self.W_) + self.b_\n",
    "\n",
    "def make_ultimate_pipeline(needed_columns: Optional[List[str]]=None,interesting_columns: Optional[List[str]]=None,lr=0.01, regularization=1., delta_converged=1e-3, max_steps=1000,\n",
    "                     batch_size=64):\n",
    "    return Pipeline([('preprocessor', OneHotPreprocessor(needed_columns=needed_columns,interesting_columns=interesting_columns)),('SGDEstimator',\n",
    "                    SGDLinearRegressor(lr,regularization,delta_converged,max_steps,batch_size))])"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpipeline\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Pipeline\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpreprocessing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StandardScaler, OneHotEncoder\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'numpy'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bb1dbb09693b2d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
